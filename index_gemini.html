<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI ë™ì „ ë„ê° v7.0 - Final Fix</title>
    <script src="https://docs.opencv.org/4.5.0/opencv.js"></script>
    <style>
        :root { --primary: #4285f4; --terminal: #1e1e1e; }
        body { font-family: sans-serif; background: #f0f2f5; margin: 0; display: flex; flex-direction: column; align-items: center; }
        header { background: #202124; color: white; width: 100%; text-align: center; padding: 15px; }
        .viewport { position: relative; width: 90%; max-width: 400px; aspect-ratio: 1/1; margin: 20px; border-radius: 20px; overflow: hidden; border: 4px solid #fff; box-shadow: 0 10px 20px rgba(0,0,0,0.2); }
        video { width: 100%; height: 100%; object-fit: cover; }
        .guide { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); width: 220px; height: 220px; border: 2px dashed #00ff00; border-radius: 50%; }
        .debug-panel { width: 90%; max-width: 400px; background: var(--terminal); color: #00ff00; padding: 15px; border-radius: 10px; font-family: monospace; font-size: 12px; height: 150px; overflow-y: auto; margin-bottom: 20px; }
        .btn-group { display: flex; gap: 10px; margin-bottom: 30px; }
        button { padding: 12px 20px; border-radius: 10px; border: none; font-weight: bold; cursor: pointer; background: var(--primary); color: white; }
        button:disabled { background: #ccc; }
        #preview-canvas { width: 150px; height: 150px; border: 2px solid var(--primary); margin-bottom: 20px; display: block; }
    </style>
</head>
<body>

<header><h1>ğŸª™ AI ë™ì „ ë„ê° v7.0</h1></header>

<div class="viewport">
    <video id="webcam" autoplay playsinline></video>
    <div class="guide"></div>
</div>

<div id="log" class="debug-panel">ì‹œìŠ¤í…œ ê°€ë™ ëŒ€ê¸° ì¤‘...</div>

<canvas id="preview-canvas"></canvas>

<div class="btn-group">
    <button id="scan-btn" disabled>ğŸ“· ë™ì „ ìŠ¤ìº”</button>
    <button onclick="location.reload()">ğŸ”„ ë¦¬ì…‹</button>
</div>

<canvas id="hidden-canvas" style="display:none;"></canvas>

<script type="module">
    // Skypackì„ í†µí•´ MediaPipeë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œ
    import vision from "https://cdn.skypack.dev/@mediapipe/tasks-vision";

    const video = document.getElementById('webcam');
    const logPanel = document.getElementById('log');
    const scanBtn = document.getElementById('scan-btn');
    const previewCanvas = document.getElementById('preview-canvas');

    let textRecognizer, videoTrack;

    function log(msg, type = 'info') {
        const color = type === 'error' ? '#ff4757' : (type === 'success' ? '#2ed573' : '#00ff00');
        logPanel.innerHTML += `<div style="color:${color}">> ${msg}</div>`;
        logPanel.scrollTop = logPanel.scrollHeight;
    }

    async function init() {
        try {
            log("1. AI ëª¨ë“ˆ ë¡œë“œ ì¤‘...", 'info');
            const { TextRecognizer, FilesetResolver } = vision;
            
            const filesetResolver = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
            );
            
            textRecognizer = await TextRecognizer.createFromOptions(filesetResolver, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/text_recognizer/text_recognizer_thin/float32/1/text_recognizer_thin.tflite",
                    delegate: "GPU"
                }
            });
            log("âœ… AI ë¡œë“œ ì„±ê³µ!", 'success');

            log("2. ì¹´ë©”ë¼ ì—°ê²° ì¤‘...", 'info');
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
            video.srcObject = stream;
            videoTrack = stream.getVideoTracks()[0];
            
            scanBtn.disabled = false;
            log("ğŸš€ ëª¨ë“  ì¤€ë¹„ ì™„ë£Œ!", 'success');

        } catch (err) {
            log("âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: " + err.message, 'error');
        }
    }

    scanBtn.onclick = async () => {
        log("ğŸ” ë¶„ì„ ì‹œì‘...", 'info');
        const ctx = previewCanvas.getContext('2d');
        previewCanvas.width = 300; previewCanvas.height = 300;
        
        // 1. ì´ë¯¸ì§€ ìº¡ì²˜
        ctx.drawImage(video, (video.videoWidth-300)/2, (video.videoHeight-300)/2, 300, 300, 0, 0, 300, 300);

        // 2. OpenCV ì „ì²˜ë¦¬ (ë³´ë‚´ì£¼ì‹  ì‚¬ì§„ì˜ 'ë¹ˆ ìˆ«ì'ë¥¼ ì±„ìš°ëŠ” ë¡œì§ ì¶”ê°€)
        if (typeof cv !== 'undefined') {
            let src = cv.imread(previewCanvas);
            cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
            
            // ìˆ«ìë¥¼ êµµê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ì²˜ë¦¬ (Closing)
            let M = cv.Mat.ones(3, 3, cv.CV_8U);
            cv.adaptiveThreshold(src, src, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2);
            cv.morphologyEx(src, src, cv.MORPH_CLOSE, M); // ë¹ˆ í‹ˆ ë©”ìš°ê¸°
            
            cv.imshow(previewCanvas, src);
            src.delete(); M.delete();
        }

        // 3. AI ì¸ì‹
        const result = await textRecognizer.recognize(previewCanvas);
        const text = result.paragraphs.map(p => p.text).join(" ");
        log(`ğŸ“¡ ì¸ì‹ ì›ë¬¸: "${text}"`, 'success');

        // 4. ê²°ê³¼ ë¶„ë¥˜
        const year = text.match(/19\d{2}|20\d{2}/)?.[0] || "ë¯¸í™•ì¸";
        const amount = text.match(/10|50|100|500/)?.[0] || "ë¯¸í™•ì¸";
        log(`ğŸ’° ìµœì¢…ë¶„ë¥˜: ${amount}ì› / ${year}ë…„`);
    };

    // OpenCV ì¤€ë¹„ ëŒ€ê¸°
    if (typeof cv !== 'undefined' && cv.onRuntimeInitialized) init();
    else setTimeout(init, 1500);
</script>
</body>
</html>