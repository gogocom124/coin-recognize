<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI Coin Collector v13.0</title>
    <script src="https://docs.opencv.org/4.5.0/opencv.js"></script>
    <style>
        :root { --primary: #4285f4; --terminal: #1e1e1e; }
        body { font-family: sans-serif; background: #f8f9fa; margin: 0; display: flex; flex-direction: column; align-items: center; }
        .viewport { position: relative; width: 90%; max-width: 380px; aspect-ratio: 1/1; margin: 15px 0; border-radius: 20px; overflow: hidden; background: #000; border: 3px solid #ddd; }
        video { width: 100%; height: 100%; object-fit: cover; }
        .guide { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); width: 200px; height: 200px; border: 2px dashed #00ff00; border-radius: 50%; pointer-events: none; }
        .debug-section { width: 90%; max-width: 400px; background: var(--terminal); color: #00ff00; border-radius: 10px; padding: 10px; font-family: monospace; font-size: 11px; height: 150px; overflow-y: auto; margin-bottom: 20px; }
        button { padding: 12px 20px; border-radius: 10px; border: none; font-weight: bold; cursor: pointer; background: var(--primary); color: white; margin-bottom: 20px; }
        button:disabled { background: #555; }
    </style>
</head>
<body>

<div class="viewport">
    <video id="webcam" autoplay playsinline></video>
    <div class="guide"></div>
</div>

<div id="log" class="debug-section">> [v13.0] ì‹œìŠ¤í…œ ì¬ì„¤ì • ì¤‘...</div>

<button id="scan-btn" disabled>ğŸ“· ë™ì „ ìŠ¤ìº” ì‹œì‘</button>

<canvas id="temp-canvas" style="display:none;"></canvas>

<script type="module">
    // [í•µì‹¬ ìˆ˜ì •] 'default' ëŒ€ì‹  ì •í™•í•œ ì´ë¦„(Named Import)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    import { TextRecognizer, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.mjs";

    const video = document.getElementById('webcam');
    const logPanel = document.getElementById('log');
    const scanBtn = document.getElementById('scan-btn');
    let textRecognizer;

    function log(msg, color = "#00ff00") {
        logPanel.innerHTML += `<div style="color:${color}">> ${msg}</div>`;
        logPanel.scrollTop = logPanel.scrollHeight;
    }

    async function init() {
        try {
            log("1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ!");
            
            log("2. AI ì—”ì§„(WASM) ì„¤ì • ì¤‘...");
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
            );
            
            log("3. í…ìŠ¤íŠ¸ ì¸ì‹ê¸°(OCR) ìƒì„± ì¤‘...");
            textRecognizer = await TextRecognizer.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/text_recognizer/text_recognizer_thin/float32/1/text_recognizer_thin.tflite",
                    delegate: "GPU"
                }
            });
            log("âœ… í…ìŠ¤íŠ¸ ì¸ì‹ê¸° ì¤€ë¹„ ì™„ë£Œ!", "#2ed573");

            log("4. ì¹´ë©”ë¼ ê°€ë™...");
            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
            video.srcObject = stream;
            
            scanBtn.disabled = false;
            log("âœ¨ ëª¨ë“  ì¤€ë¹„ ë! ìŠ¤ìº” ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.", "#fff");

        } catch (err) {
            log("âŒ ì˜¤ë¥˜ ë°œìƒ: " + err.message, "#ff4757");
            // ë§Œì•½ TextRecognizerê°€ ì—†ë‹¤ëŠ” ì—ëŸ¬ê°€ ë‚˜ë©´ ì—¬ê¸°ì„œ ì¡í™ë‹ˆë‹¤.
        }
    }

    scanBtn.onclick = async () => {
        log("ğŸ” ë¶„ì„ ì¤‘...");
        const canvas = document.getElementById('temp-canvas');
        canvas.width = 300; canvas.height = 300;
        canvas.getContext('2d').drawImage(video, (video.videoWidth-300)/2, (video.videoHeight-300)/2, 300, 300, 0, 0, 300, 300);

        // [OpenCV ì „ì²˜ë¦¬] ì†ì´ ë¹ˆ ê¸€ì ì±„ìš°ê¸°
        if (typeof cv !== 'undefined') {
            try {
                let src = cv.imread(canvas);
                cv.cvtColor(src, src, cv.COLOR_RGBA2GRAY);
                cv.convertScaleAbs(src, src, 1.3, 0); // ëŒ€ë¹„ ì¦ê°€
                cv.threshold(src, src, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU);
                
                // ëª¨í´ë¡œì§€ ë‹«ê¸° ì—°ì‚° (ëŠì–´ì§„ ê¸€ì ì—°ê²°)
                let M = cv.Mat.ones(3, 3, cv.CV_8U);
                cv.morphologyEx(src, src, cv.MORPH_CLOSE, M);
                
                // ë‹¤ì‹œ ë°˜ì „ (í° ë°°ê²½ ê²€ì€ ê¸€ì)
                cv.bitwise_not(src, src);
                cv.imshow(canvas, src);
                src.delete(); M.delete();
            } catch(e) { console.log("OpenCV ì˜¤ë¥˜ ë¬´ì‹œ"); }
        }

        const result = await textRecognizer.recognize(canvas);
        const text = result.paragraphs.map(p => p.text).join(" ");
        log(`ğŸ“¡ ì¸ì‹ ì›ë¬¸: "${text || 'ì½ê¸° ì‹¤íŒ¨'}"`, "#ffc107");
        
        // ê°„ë‹¨í•œ ê²°ê³¼ íŒŒì‹±
        const year = text.match(/19\d{2}|20\d{2}/)?.[0];
        if (year) log(`ğŸ“… ì—°ë„ ë°œê²¬: ${year}ë…„`, "#fff");
    };

    setTimeout(init, 1000);
</script>
</body>
</html>